name: Data Pipeline

# DISABLED - Amadeus API quota exhausted.
# Manual trigger only, no cron. Do not run until API quota is renewed.

on:
  workflow_dispatch:
    inputs:
      dbt_only:
        description: "Skip ingestion, only run dbt transforms (uses existing silver data)"
        required: false
        default: "false"
        type: choice
        options: ["false", "true"]
      skip_dbt:
        description: "Skip dbt transforms (ingestion only)"
        required: false
        default: "false"
        type: choice
        options: ["false", "true"]
      full_refresh:
        description: "Full refresh dbt models (clears and rebuilds incrementals)"
        required: false
        default: "false"
        type: choice
        options: ["false", "true"]

env:
  WAREHOUSE_URL: ${{ secrets.WAREHOUSE_URL }}
  PGSSLMODE: require
  # Individual params kept for dbt profiles.yml
  DBT_HOST: ${{ secrets.RENDER_DB_HOST }}
  DBT_USER: ${{ secrets.RENDER_DB_USER }}
  DBT_PASS: ${{ secrets.RENDER_DB_PASSWORD }}
  DBT_DBNAME: ${{ secrets.RENDER_DB_NAME }}
  # Amadeus API â€” using test/sandbox credentials for now
  AMADEUS_CLIENT_ID: ${{ secrets.AMADEUS_CLIENT_ID }}
  AMADEUS_CLIENT_SECRET: ${{ secrets.AMADEUS_CLIENT_SECRET }}
  AMADEUS_ENV: "test"

jobs:
  # Job 1: ensure DB tables exist before any parallel ingest starts
  setup:
    name: Setup warehouse tables
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: ${{ github.event.inputs.dbt_only != 'true' }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: pip
          cache-dependency-path: data/scripts/requirements.txt

      - run: pip install -r data/scripts/requirements.txt

      - name: Create bronze tables (idempotent)
        working-directory: data/scripts
        run: python -c "from db_utils import setup_bronze_tables; setup_bronze_tables()"

  # Job 2: ingest one airport per parallel runner
  ingest:
    name: Ingest ${{ matrix.airport }}
    needs: setup
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: ${{ github.event.inputs.dbt_only != 'true' }}
    strategy:
      matrix:
        airport: [CDG, ORY, LYS, MRS, BOD, NTE, NCE, TLS, LIL]
      fail-fast: false

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: pip
          cache-dependency-path: data/scripts/requirements.txt

      - run: pip install -r data/scripts/requirements.txt

      - name: Ingest flights from ${{ matrix.airport }}
        working-directory: data/scripts
        env:
          AIRPORT: ${{ matrix.airport }}
        run: python ingest_flights.py --airport "$AIRPORT"

  # Job 3: dbt transforms (runs after ingest, or standalone when dbt_only=true)
  transform:
    name: dbt transforms
    needs: [ingest]
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: |
      always() &&
      github.event.inputs.skip_dbt != 'true' &&
      (github.event.inputs.dbt_only == 'true' || needs.ingest.result == 'success')

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: pip
          cache-dependency-path: data/scripts/requirements.txt

      - run: pip install -r data/scripts/requirements.txt

      - run: pip install dbt-postgres==1.8.0

      - name: Run dbt transforms
        working-directory: data/dbt
        env:
          FULL_REFRESH: ${{ github.event.inputs.full_refresh }}
        run: |
          dbt deps
          dbt seed --target prod
          if [ "$FULL_REFRESH" = "true" ]; then
            dbt run --target prod --exclude silver_hostels gold_combo_deals --full-refresh
          else
            dbt run --target prod --exclude silver_hostels gold_combo_deals
          fi
          dbt test --target prod --exclude silver_hostels gold_combo_deals --store-failures
